{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Index Data Framework\n",
    "General index data input using a test dataset of ~750 manuscripts\n",
    "across 2 topics: Antediluvian and Hennig86. \n",
    "\n",
    "---\n",
    "Created 6/3/22 by Ian Hay   \n",
    "Updated 7/23/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Dependencies\n",
    "\n",
    "---\n",
    "[Python 3.8+](https://www.python.org/downloads/release/python-380/)    \n",
    "[Pandas](https://pandas.pydata.org/)   \n",
    "[NumPy](https://numpy.org/)    \n",
    "[scikit-learn](https://scikit-learn.org/stable/index.html)  \n",
    "[nltk](https://www.nltk.org/)   \n",
    "[spacy](https://pypi.org/project/spacy/)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import ssl\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run in python environment: \n",
    "\n",
    "python -m spacy download en_core_web_sm\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ianha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing -------------------------------------------------------------------------------------------\n",
    "\n",
    "def getDocColumn(df, column, newColumnName):\n",
    "    \"\"\"\n",
    "    Given a dataframe and a column of datatype list, constructs\n",
    "    a new column newColumnName with the list joined into a single\n",
    "    string and items separated by spaces (\" \").\n",
    "    \"\"\"\n",
    "    strDict = {}\n",
    "    for row in range(len(df)):\n",
    "        text = \". \".join(df.iloc[row][column])\n",
    "        text = text + \".\"\n",
    "        strDict[df.index[row]] = text\n",
    "    dfStr = pd.Series(strDict, name=newColumnName)\n",
    "    df[newColumnName] = dfStr\n",
    "\n",
    "def partOfSpeechTagging(texts, POS=[\"NOUN\", \"ADJ\", \"ADV\", \"VERB\"]):\n",
    "    \"\"\"\n",
    "    Utilizes Spacy to extract nouns and verbs from ngrams\n",
    "    and build a new column with only these terms.\n",
    "    https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#16buildingldamalletmodel\n",
    "    \"\"\"\n",
    "    textTagged = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        text_ = [token.lemma_ for token in doc if token.pos_ in POS]\n",
    "        textTagged.append(\" \".join(text_))\n",
    "    return textTagged\n",
    "\n",
    "def removeStopWords(texts):\n",
    "    \"\"\"\n",
    "    Takes in texts (words in a single string separated by spaces).\n",
    "    https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "    \"\"\"\n",
    "    textParsed = []\n",
    "    from nltk.corpus import stopwords\n",
    "    _stopWords = stopwords.words(\"english\")\n",
    "    _stopWords.extend([\"-pron-\", \"pron\"]) # these words appears in many ngrams without apparent meaning\n",
    "    textParsed = texts.apply(lambda x: \" \".join([word for word in x.split() if word not in (list(_stopWords))]))\n",
    "    return textParsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility --------------------------------------------------------------------------------------------------\n",
    "\n",
    "def loadTextFileIntoDataframe(filepath, columns, splittingChar=\"\\t\"):\n",
    "    \"\"\"\n",
    "    Opens the given filepath into a pandas dataframe.\n",
    "    Splits the list by the denoted character, by default tab.\n",
    "    Returns a pandas dataframe.\n",
    "    \"\"\"\n",
    "    with open(filepath) as file:\n",
    "        data = file.readlines()\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for line in data:\n",
    "        lineSplit = [line.split(splittingChar)]\n",
    "        if len(lineSplit[0]) < len(columns):\n",
    "            for x in range(len(columns) - len(lineSplit[0])):\n",
    "                lineSplit[0].append(\"0\")\n",
    "        lineDF = pd.DataFrame(lineSplit, columns=columns)\n",
    "        df = pd.concat([df, lineDF], axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def standardizeDataColumn(df, column, newColumnName):\n",
    "    \"\"\"\n",
    "    Standardizes the column of the dataframe df.\n",
    "    Adds the new column newColumnName to the dataframe inplace.\n",
    "    Utilizes SKLearn.preprocessing.standardscaler.\n",
    "    Mean is 0, variance is 1\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaledSeries = pd.Series(np.reshape(scaler.fit_transform(np.array(df[column]).reshape(-1, 1)), (-1)), name=newColumnName, index=df.index)\n",
    "    scaledSeries = scaledSeries + 1 # adding 1 scales most (~98%) to be in range [0, 2] for graphing purposes\n",
    "    df[newColumnName] = scaledSeries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Dataframe and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded things\n",
    "columnListNGrams = [\"hash\", \"ngram\", \"ngram_lc\", \"ngram_tokens\", \"ngram_count\", \"term_freq\", \"doc_count\", \"date_added\"]\n",
    "columnListKeywords = [\"hash\", \"keywords\", \"keywords_lc\", \"keyword_tokens\", \"keyword_score\", \"doc_count\", \"insert_date\"]\n",
    "\n",
    "non_words = [\"a\", \"at\", \"an\", \"am\", \"and\", \"that\", \"like\", \"for\", \"by\", \"i\", \"in\", \"of\", \"or\", \"be\", \"use\", \"as\", \"on\", \"the\", \"to\", \"with\", \"-pron-\"]\n",
    "\n",
    "filenameAnteNGrams = \"data/doc_ngrams/sample.fgrep.antediluvian.txt\"\n",
    "filepathHennigNGrams = \"data/doc_ngrams/sample.fgrep.Hennig86.txt\"\n",
    "filenameAnteKeywords = \"data/doc_keywords/sample.fgrep.antediluvian.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>ngram_lc</th>\n",
       "      <th>ngram_tokens</th>\n",
       "      <th>ngram_count</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>doc_count</th>\n",
       "      <th>date_added</th>\n",
       "      <th>topic</th>\n",
       "      <th>ngram_lc_tagged</th>\n",
       "      <th>normalized_term_freq</th>\n",
       "      <th>ngram_lc_tagged_doc</th>\n",
       "      <th>ngram_lc_doc</th>\n",
       "      <th>topic_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3002e8a37ec9d00a67bdf0004b8628c35d72068d</th>\n",
       "      <td>[antediluvian, antediluvian humanity]</td>\n",
       "      <td>[antediluvian, antediluvian humanity]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[\\N\\n, \\N\\n]</td>\n",
       "      <td>antediluvian</td>\n",
       "      <td>[antediluvian, antediluvian humanity]</td>\n",
       "      <td>0.345035</td>\n",
       "      <td>antediluvian. antediluvian humanity.</td>\n",
       "      <td>antediluvian. antediluvian humanity.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005b3bf055ddcb3c25e4742a72ee16728934efd</th>\n",
       "      <td>[antediluvian, antediluvian refrain, follow by...</td>\n",
       "      <td>[antediluvian, antediluvian refrain, follow by...</td>\n",
       "      <td>[1, 2, 4, 5]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[\\N\\n, \\N\\n, \\N\\n, \\N\\n]</td>\n",
       "      <td>antediluvian</td>\n",
       "      <td>[antediluvian, refrain, follow antediluvian, f...</td>\n",
       "      <td>0.995948</td>\n",
       "      <td>antediluvian. refrain. follow antediluvian. fo...</td>\n",
       "      <td>antediluvian. antediluvian refrain. follow by ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005ebfe5508340797dbfcce8454f3d3f6f76eb1</th>\n",
       "      <td>[antediluvian, antediluvian dream, cave of -PR...</td>\n",
       "      <td>[antediluvian, antediluvian dream, cave of -pr...</td>\n",
       "      <td>[1, 2, 4, 5, 5]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[2021-09-03\\n, 2021-09-03\\n, 2021-09-03\\n, 202...</td>\n",
       "      <td>antediluvian</td>\n",
       "      <td>[antediluvian, antediluvian dream, antediluvia...</td>\n",
       "      <td>0.540615</td>\n",
       "      <td>antediluvian. antediluvian dream. antediluvian...</td>\n",
       "      <td>antediluvian. antediluvian dream. cave of -pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30064ae161de1e9a96992be108c195796f13e72a</th>\n",
       "      <td>[Hennig86 program, routine in the Hennig86, ro...</td>\n",
       "      <td>[hennig86 program, routine in the hennig86, ro...</td>\n",
       "      <td>[2, 4, 5, 1]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[\\N\\n, \\N\\n, \\N\\n, \\N\\n]</td>\n",
       "      <td>hennig86</td>\n",
       "      <td>[program, routine hennig86, routine hennig86 p...</td>\n",
       "      <td>0.797378</td>\n",
       "      <td>program. routine hennig86. routine hennig86 pr...</td>\n",
       "      <td>hennig86 program. routine in the hennig86. rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30136ab3788ab8e8be6b939901ec669a41ef896a</th>\n",
       "      <td>[antediluvian]</td>\n",
       "      <td>[antediluvian]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\\N\\n]</td>\n",
       "      <td>antediluvian</td>\n",
       "      <td>[antediluvian]</td>\n",
       "      <td>0.443641</td>\n",
       "      <td>antediluvian.</td>\n",
       "      <td>antediluvian.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      ngram  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              [antediluvian, antediluvian humanity]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  [antediluvian, antediluvian refrain, follow by...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [antediluvian, antediluvian dream, cave of -PR...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  [Hennig86 program, routine in the Hennig86, ro...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                     [antediluvian]   \n",
       "\n",
       "                                                                                   ngram_lc  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              [antediluvian, antediluvian humanity]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  [antediluvian, antediluvian refrain, follow by...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [antediluvian, antediluvian dream, cave of -pr...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  [hennig86 program, routine in the hennig86, ro...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                     [antediluvian]   \n",
       "\n",
       "                                             ngram_tokens      ngram_count  \\\n",
       "hash                                                                         \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d           [1, 2]           [1, 1]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd     [1, 2, 4, 5]     [1, 1, 1, 1]   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [1, 2, 4, 5, 5]  [1, 1, 1, 1, 1]   \n",
       "30064ae161de1e9a96992be108c195796f13e72a     [2, 4, 5, 1]     [1, 1, 1, 1]   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a              [1]              [1]   \n",
       "\n",
       "                                          term_freq        doc_count  \\\n",
       "hash                                                                   \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d   0.000010           [1, 1]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd   0.000281     [1, 1, 1, 1]   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1   0.000091  [1, 1, 1, 1, 1]   \n",
       "30064ae161de1e9a96992be108c195796f13e72a   0.000198     [1, 1, 1, 1]   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a   0.000051              [1]   \n",
       "\n",
       "                                                                                 date_added  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d                                       [\\N\\n, \\N\\n]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd                           [\\N\\n, \\N\\n, \\N\\n, \\N\\n]   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [2021-09-03\\n, 2021-09-03\\n, 2021-09-03\\n, 202...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a                           [\\N\\n, \\N\\n, \\N\\n, \\N\\n]   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                             [\\N\\n]   \n",
       "\n",
       "                                                 topic  \\\n",
       "hash                                                     \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d  antediluvian   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  antediluvian   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  antediluvian   \n",
       "30064ae161de1e9a96992be108c195796f13e72a      hennig86   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a  antediluvian   \n",
       "\n",
       "                                                                            ngram_lc_tagged  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              [antediluvian, antediluvian humanity]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  [antediluvian, refrain, follow antediluvian, f...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [antediluvian, antediluvian dream, antediluvia...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  [program, routine hennig86, routine hennig86 p...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                     [antediluvian]   \n",
       "\n",
       "                                          normalized_term_freq  \\\n",
       "hash                                                             \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              0.345035   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd              0.995948   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1              0.540615   \n",
       "30064ae161de1e9a96992be108c195796f13e72a              0.797378   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a              0.443641   \n",
       "\n",
       "                                                                        ngram_lc_tagged_doc  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d               antediluvian. antediluvian humanity.   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  antediluvian. refrain. follow antediluvian. fo...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  antediluvian. antediluvian dream. antediluvian...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  program. routine hennig86. routine hennig86 pr...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                      antediluvian.   \n",
       "\n",
       "                                                                               ngram_lc_doc  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d               antediluvian. antediluvian humanity.   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  antediluvian. antediluvian refrain. follow by ...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  antediluvian. antediluvian dream. cave of -pro...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  hennig86 program. routine in the hennig86. rou...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                      antediluvian.   \n",
       "\n",
       "                                          topic_num  \n",
       "hash                                                 \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d          1  \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd          1  \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1          1  \n",
       "30064ae161de1e9a96992be108c195796f13e72a          0  \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test files into dataframe\n",
    "\n",
    "indexCol = columnListNGrams[0]\n",
    "df_antedivulian = loadTextFileIntoDataframe(filepath=filenameAnteNGrams, columns=columnListNGrams)\n",
    "df_hennig = loadTextFileIntoDataframe(filepath=filepathHennigNGrams, columns=columnListNGrams)\n",
    "df_antedivulian[\"topic\"] = \"antediluvian\"\n",
    "df_hennig[\"topic\"] = \"hennig86\"\n",
    "df = pd.concat([df_antedivulian, df_hennig])\n",
    "\n",
    "# process data columns\n",
    "df[\"ngram_lc_tagged\"] = partOfSpeechTagging(df[\"ngram_lc\"])\n",
    "df[\"ngram_lc_tagged\"] = removeStopWords(df[\"ngram_lc_tagged\"])\n",
    "df = df.groupby(indexCol).agg(list)\n",
    "\n",
    "yakeScoreCol = columnListNGrams[5]\n",
    "for n in range(len(df)):\n",
    "    term_freq_list = df[yakeScoreCol].iloc[n]\n",
    "    df[yakeScoreCol].iloc[n] = term_freq_list[0]\n",
    "    df[\"topic\"].iloc[n] = df[\"topic\"].iloc[n][0]\n",
    "    if (len(df[\"ngram_lc_tagged\"].iloc[n])) == 0: # if there are no noun/verb phrases from spacy preprocessing\n",
    "        df[\"ngram_lc_tagged\"][n] = df[\"ngram_lc\"].iloc[n] # replace it with the lowercase ngram(s)\n",
    "df[yakeScoreCol] = df[yakeScoreCol].astype(float)\n",
    "\n",
    "standardizeDataColumn(df, yakeScoreCol, \"normalized_term_freq\")\n",
    "getDocColumn(df, \"ngram_lc_tagged\", \"ngram_lc_tagged_doc\")\n",
    "getDocColumn(df, \"ngram_lc\", \"ngram_lc_doc\")\n",
    "df[\"topic_num\"] = (df[\"topic\"] == \"antediluvian\").astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of all words that appear in the dataset\n",
    "\n",
    "from itertools import chain\n",
    "masterTermList = []\n",
    "for eachList in df[\"ngram_lc\"].values:\n",
    "    splitList = []\n",
    "    for string in eachList:\n",
    "        splitList.append(string.split(\" \"))\n",
    "    masterTermList.append(splitList)\n",
    "firstNest = list(chain(*masterTermList))\n",
    "secondNest = list(chain(*firstNest))\n",
    "masterTerms = list(dict.fromkeys(secondNest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74a87f91cde4fc93505a958135b0eb2fe5f761a6a4ac2799970d07df29216479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
